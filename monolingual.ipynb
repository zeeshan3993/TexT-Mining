{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arkbhayani\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\arkbhayani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "import gensim.models.word2vec as w2v #process row data\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arkbhayani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Give file path with name and extension \n",
    "#row_data_file = 'data\\sample.txt' \n",
    "row_data_file = 'data\\Europarl.de-en.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess on row data\n",
    "# create word token\n",
    "# remove stop word\n",
    "# take lower case data and applay lemmatizetion on it\n",
    "# take only alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = u\"\"\n",
    "token_line = []\n",
    "without_stop_word = []\n",
    "filter_data = []\n",
    "clean_data = []\n",
    "stop_words = set(stopwords.words('english')) #stop word\n",
    "wl = WordNetLemmatizer()\n",
    "temp_file = open('temp.txt', \"w\")\n",
    "\n",
    "with codecs.open(row_data_file, \"r\", \"utf-8\") as book_file:\n",
    "       for line in book_file:\n",
    "            token_line_first = word_tokenize(line.lower())\n",
    "            without_stop_word = [w for w in token_line_first if not w in stop_words]\n",
    "            filter_data = [wl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wl.lemmatize(i) for i,j in pos_tag(without_stop_word)]\n",
    "            for clean_row_data in filter_data:\n",
    "                   clean_data.append(re.sub(\"[^a-zA-Z]\",\" \", clean_row_data))\n",
    "            temp_file.writelines( \" \".join( clean_data)+\"\\n\" )\n",
    "            clean_data = []                \n",
    "temp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read data from file which alredy preprocessed data\n",
    "clean_raw_data = \"\"\n",
    "token_line_first = []\n",
    "with codecs.open('temp.txt', \"r\", \"utf-8\") as book_file:\n",
    "        for line in book_file:\n",
    "            token_line_first.append(word_tokenize(line))\n",
    "book_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform Distance, similarity and ranking \n",
    "num_features = 120\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mulLanguage = w2v.Word2Vec(\n",
    "    sg=0,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:28:06,768 : INFO : collecting all words and their counts\n",
      "2017-10-12 16:28:06,798 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-10-12 16:28:06,995 : INFO : PROGRESS: at sentence #10000, processed 127090 words, keeping 8124 word types\n",
      "2017-10-12 16:28:07,045 : INFO : PROGRESS: at sentence #20000, processed 254164 words, keeping 11190 word types\n",
      "2017-10-12 16:28:07,100 : INFO : PROGRESS: at sentence #30000, processed 382191 words, keeping 13358 word types\n",
      "2017-10-12 16:28:07,145 : INFO : PROGRESS: at sentence #40000, processed 504576 words, keeping 14994 word types\n",
      "2017-10-12 16:28:07,192 : INFO : PROGRESS: at sentence #50000, processed 627340 words, keeping 16249 word types\n",
      "2017-10-12 16:28:07,238 : INFO : PROGRESS: at sentence #60000, processed 751067 words, keeping 17440 word types\n",
      "2017-10-12 16:28:07,295 : INFO : PROGRESS: at sentence #70000, processed 880596 words, keeping 18325 word types\n",
      "2017-10-12 16:28:07,351 : INFO : PROGRESS: at sentence #80000, processed 1006466 words, keeping 19221 word types\n",
      "2017-10-12 16:28:07,412 : INFO : PROGRESS: at sentence #90000, processed 1133818 words, keeping 20163 word types\n",
      "2017-10-12 16:28:07,459 : INFO : PROGRESS: at sentence #100000, processed 1262013 words, keeping 20996 word types\n",
      "2017-10-12 16:28:07,509 : INFO : PROGRESS: at sentence #110000, processed 1391651 words, keeping 21766 word types\n",
      "2017-10-12 16:28:07,567 : INFO : PROGRESS: at sentence #120000, processed 1521597 words, keeping 22432 word types\n",
      "2017-10-12 16:28:07,615 : INFO : PROGRESS: at sentence #130000, processed 1649819 words, keeping 23028 word types\n",
      "2017-10-12 16:28:07,681 : INFO : PROGRESS: at sentence #140000, processed 1773847 words, keeping 23805 word types\n",
      "2017-10-12 16:28:07,730 : INFO : PROGRESS: at sentence #150000, processed 1905171 words, keeping 24452 word types\n",
      "2017-10-12 16:28:07,798 : INFO : PROGRESS: at sentence #160000, processed 2031584 words, keeping 25026 word types\n",
      "2017-10-12 16:28:07,856 : INFO : PROGRESS: at sentence #170000, processed 2156641 words, keeping 25608 word types\n",
      "2017-10-12 16:28:07,916 : INFO : PROGRESS: at sentence #180000, processed 2277789 words, keeping 26196 word types\n",
      "2017-10-12 16:28:07,969 : INFO : PROGRESS: at sentence #190000, processed 2403179 words, keeping 26777 word types\n",
      "2017-10-12 16:28:08,021 : INFO : PROGRESS: at sentence #200000, processed 2527599 words, keeping 27285 word types\n",
      "2017-10-12 16:28:08,079 : INFO : PROGRESS: at sentence #210000, processed 2652570 words, keeping 27845 word types\n",
      "2017-10-12 16:28:08,128 : INFO : PROGRESS: at sentence #220000, processed 2775283 words, keeping 28364 word types\n",
      "2017-10-12 16:28:08,186 : INFO : PROGRESS: at sentence #230000, processed 2902946 words, keeping 28918 word types\n",
      "2017-10-12 16:28:08,237 : INFO : PROGRESS: at sentence #240000, processed 3031118 words, keeping 29388 word types\n",
      "2017-10-12 16:28:08,289 : INFO : PROGRESS: at sentence #250000, processed 3156491 words, keeping 29823 word types\n",
      "2017-10-12 16:28:08,339 : INFO : PROGRESS: at sentence #260000, processed 3285848 words, keeping 30274 word types\n",
      "2017-10-12 16:28:08,389 : INFO : PROGRESS: at sentence #270000, processed 3415190 words, keeping 30669 word types\n",
      "2017-10-12 16:28:08,440 : INFO : PROGRESS: at sentence #280000, processed 3537973 words, keeping 31170 word types\n",
      "2017-10-12 16:28:08,494 : INFO : PROGRESS: at sentence #290000, processed 3663962 words, keeping 31535 word types\n",
      "2017-10-12 16:28:08,558 : INFO : PROGRESS: at sentence #300000, processed 3799661 words, keeping 31934 word types\n",
      "2017-10-12 16:28:08,619 : INFO : PROGRESS: at sentence #310000, processed 3930384 words, keeping 32336 word types\n",
      "2017-10-12 16:28:08,674 : INFO : PROGRESS: at sentence #320000, processed 4065589 words, keeping 32738 word types\n",
      "2017-10-12 16:28:08,726 : INFO : PROGRESS: at sentence #330000, processed 4200060 words, keeping 33133 word types\n",
      "2017-10-12 16:28:08,770 : INFO : PROGRESS: at sentence #340000, processed 4331577 words, keeping 33471 word types\n",
      "2017-10-12 16:28:08,819 : INFO : PROGRESS: at sentence #350000, processed 4461289 words, keeping 33849 word types\n",
      "2017-10-12 16:28:08,882 : INFO : PROGRESS: at sentence #360000, processed 4590176 words, keeping 34160 word types\n",
      "2017-10-12 16:28:08,985 : INFO : PROGRESS: at sentence #370000, processed 4715563 words, keeping 34433 word types\n",
      "2017-10-12 16:28:09,044 : INFO : PROGRESS: at sentence #380000, processed 4840017 words, keeping 34716 word types\n",
      "2017-10-12 16:28:09,090 : INFO : PROGRESS: at sentence #390000, processed 4966166 words, keeping 35066 word types\n",
      "2017-10-12 16:28:09,141 : INFO : PROGRESS: at sentence #400000, processed 5090142 words, keeping 35399 word types\n",
      "2017-10-12 16:28:09,188 : INFO : PROGRESS: at sentence #410000, processed 5218092 words, keeping 35727 word types\n",
      "2017-10-12 16:28:09,256 : INFO : PROGRESS: at sentence #420000, processed 5350755 words, keeping 36054 word types\n",
      "2017-10-12 16:28:09,307 : INFO : PROGRESS: at sentence #430000, processed 5478486 words, keeping 36396 word types\n",
      "2017-10-12 16:28:09,363 : INFO : PROGRESS: at sentence #440000, processed 5608602 words, keeping 36737 word types\n",
      "2017-10-12 16:28:09,409 : INFO : PROGRESS: at sentence #450000, processed 5735737 words, keeping 37095 word types\n",
      "2017-10-12 16:28:09,452 : INFO : PROGRESS: at sentence #460000, processed 5864005 words, keeping 37391 word types\n",
      "2017-10-12 16:28:09,497 : INFO : PROGRESS: at sentence #470000, processed 5992954 words, keeping 37698 word types\n",
      "2017-10-12 16:28:09,544 : INFO : PROGRESS: at sentence #480000, processed 6122768 words, keeping 38012 word types\n",
      "2017-10-12 16:28:09,592 : INFO : PROGRESS: at sentence #490000, processed 6252466 words, keeping 38356 word types\n",
      "2017-10-12 16:28:09,645 : INFO : PROGRESS: at sentence #500000, processed 6378918 words, keeping 38681 word types\n",
      "2017-10-12 16:28:09,692 : INFO : PROGRESS: at sentence #510000, processed 6506175 words, keeping 39028 word types\n",
      "2017-10-12 16:28:09,752 : INFO : PROGRESS: at sentence #520000, processed 6636592 words, keeping 39341 word types\n",
      "2017-10-12 16:28:09,817 : INFO : PROGRESS: at sentence #530000, processed 6763646 words, keeping 39628 word types\n",
      "2017-10-12 16:28:09,876 : INFO : PROGRESS: at sentence #540000, processed 6890035 words, keeping 39921 word types\n",
      "2017-10-12 16:28:09,935 : INFO : PROGRESS: at sentence #550000, processed 7019691 words, keeping 40200 word types\n",
      "2017-10-12 16:28:10,006 : INFO : PROGRESS: at sentence #560000, processed 7145891 words, keeping 40484 word types\n",
      "2017-10-12 16:28:10,057 : INFO : PROGRESS: at sentence #570000, processed 7272386 words, keeping 40781 word types\n",
      "2017-10-12 16:28:10,134 : INFO : PROGRESS: at sentence #580000, processed 7398802 words, keeping 41021 word types\n",
      "2017-10-12 16:28:10,180 : INFO : PROGRESS: at sentence #590000, processed 7521375 words, keeping 41425 word types\n",
      "2017-10-12 16:28:10,235 : INFO : PROGRESS: at sentence #600000, processed 7646204 words, keeping 41771 word types\n",
      "2017-10-12 16:28:10,319 : INFO : PROGRESS: at sentence #610000, processed 7767319 words, keeping 42064 word types\n",
      "2017-10-12 16:28:10,386 : INFO : PROGRESS: at sentence #620000, processed 7889581 words, keeping 42302 word types\n",
      "2017-10-12 16:28:10,472 : INFO : PROGRESS: at sentence #630000, processed 8014924 words, keeping 42577 word types\n",
      "2017-10-12 16:28:10,548 : INFO : PROGRESS: at sentence #640000, processed 8139735 words, keeping 42815 word types\n",
      "2017-10-12 16:28:10,622 : INFO : PROGRESS: at sentence #650000, processed 8268283 words, keeping 43115 word types\n",
      "2017-10-12 16:28:10,684 : INFO : PROGRESS: at sentence #660000, processed 8392899 words, keeping 43462 word types\n",
      "2017-10-12 16:28:10,742 : INFO : PROGRESS: at sentence #670000, processed 8515697 words, keeping 43778 word types\n",
      "2017-10-12 16:28:10,811 : INFO : PROGRESS: at sentence #680000, processed 8640654 words, keeping 44040 word types\n",
      "2017-10-12 16:28:10,858 : INFO : PROGRESS: at sentence #690000, processed 8768850 words, keeping 44332 word types\n",
      "2017-10-12 16:28:10,918 : INFO : PROGRESS: at sentence #700000, processed 8893779 words, keeping 44620 word types\n",
      "2017-10-12 16:28:10,977 : INFO : PROGRESS: at sentence #710000, processed 9017518 words, keeping 44909 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:28:11,053 : INFO : PROGRESS: at sentence #720000, processed 9141365 words, keeping 45143 word types\n",
      "2017-10-12 16:28:11,130 : INFO : PROGRESS: at sentence #730000, processed 9267044 words, keeping 45363 word types\n",
      "2017-10-12 16:28:11,210 : INFO : PROGRESS: at sentence #740000, processed 9391622 words, keeping 45582 word types\n",
      "2017-10-12 16:28:11,275 : INFO : PROGRESS: at sentence #750000, processed 9513559 words, keeping 45820 word types\n",
      "2017-10-12 16:28:11,330 : INFO : PROGRESS: at sentence #760000, processed 9640443 words, keeping 46034 word types\n",
      "2017-10-12 16:28:11,393 : INFO : PROGRESS: at sentence #770000, processed 9763026 words, keeping 46276 word types\n",
      "2017-10-12 16:28:11,427 : INFO : PROGRESS: at sentence #780000, processed 9887136 words, keeping 46473 word types\n",
      "2017-10-12 16:28:11,496 : INFO : PROGRESS: at sentence #790000, processed 10013209 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,551 : INFO : PROGRESS: at sentence #800000, processed 10138950 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,600 : INFO : PROGRESS: at sentence #810000, processed 10268040 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,672 : INFO : PROGRESS: at sentence #820000, processed 10395219 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,736 : INFO : PROGRESS: at sentence #830000, processed 10517174 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,783 : INFO : PROGRESS: at sentence #840000, processed 10640353 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,851 : INFO : PROGRESS: at sentence #850000, processed 10764396 words, keeping 46636 word types\n",
      "2017-10-12 16:28:11,935 : INFO : PROGRESS: at sentence #860000, processed 10894176 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,009 : INFO : PROGRESS: at sentence #870000, processed 11021257 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,055 : INFO : PROGRESS: at sentence #880000, processed 11149553 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,123 : INFO : PROGRESS: at sentence #890000, processed 11275910 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,156 : INFO : PROGRESS: at sentence #900000, processed 11404360 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,225 : INFO : PROGRESS: at sentence #910000, processed 11534658 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,279 : INFO : PROGRESS: at sentence #920000, processed 11659906 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,356 : INFO : PROGRESS: at sentence #930000, processed 11788908 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,433 : INFO : PROGRESS: at sentence #940000, processed 11917636 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,518 : INFO : PROGRESS: at sentence #950000, processed 12042653 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,589 : INFO : PROGRESS: at sentence #960000, processed 12168417 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,660 : INFO : PROGRESS: at sentence #970000, processed 12290968 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,707 : INFO : PROGRESS: at sentence #980000, processed 12416281 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,780 : INFO : PROGRESS: at sentence #990000, processed 12539175 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,833 : INFO : PROGRESS: at sentence #1000000, processed 12663054 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,918 : INFO : PROGRESS: at sentence #1010000, processed 12789460 words, keeping 46636 word types\n",
      "2017-10-12 16:28:12,998 : INFO : PROGRESS: at sentence #1020000, processed 12915997 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,076 : INFO : PROGRESS: at sentence #1030000, processed 13044312 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,149 : INFO : PROGRESS: at sentence #1040000, processed 13170678 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,226 : INFO : PROGRESS: at sentence #1050000, processed 13299504 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,293 : INFO : PROGRESS: at sentence #1060000, processed 13428458 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,370 : INFO : PROGRESS: at sentence #1070000, processed 13550896 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,442 : INFO : PROGRESS: at sentence #1080000, processed 13681669 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,494 : INFO : PROGRESS: at sentence #1090000, processed 13811729 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,559 : INFO : PROGRESS: at sentence #1100000, processed 13944616 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,629 : INFO : PROGRESS: at sentence #1110000, processed 14082546 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,704 : INFO : PROGRESS: at sentence #1120000, processed 14215735 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,773 : INFO : PROGRESS: at sentence #1130000, processed 14345223 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,846 : INFO : PROGRESS: at sentence #1140000, processed 14474257 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,912 : INFO : PROGRESS: at sentence #1150000, processed 14602226 words, keeping 46636 word types\n",
      "2017-10-12 16:28:13,976 : INFO : PROGRESS: at sentence #1160000, processed 14728097 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,043 : INFO : PROGRESS: at sentence #1170000, processed 14853322 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,103 : INFO : PROGRESS: at sentence #1180000, processed 14977546 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,150 : INFO : PROGRESS: at sentence #1190000, processed 15101940 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,223 : INFO : PROGRESS: at sentence #1200000, processed 15232972 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,286 : INFO : PROGRESS: at sentence #1210000, processed 15364507 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,364 : INFO : PROGRESS: at sentence #1220000, processed 15493283 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,434 : INFO : PROGRESS: at sentence #1230000, processed 15621445 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,492 : INFO : PROGRESS: at sentence #1240000, processed 15748869 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,568 : INFO : PROGRESS: at sentence #1250000, processed 15879223 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,635 : INFO : PROGRESS: at sentence #1260000, processed 16007742 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,708 : INFO : PROGRESS: at sentence #1270000, processed 16137940 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,782 : INFO : PROGRESS: at sentence #1280000, processed 16265344 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,852 : INFO : PROGRESS: at sentence #1290000, processed 16392072 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,922 : INFO : PROGRESS: at sentence #1300000, processed 16520611 words, keeping 46636 word types\n",
      "2017-10-12 16:28:14,978 : INFO : PROGRESS: at sentence #1310000, processed 16650750 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,023 : INFO : PROGRESS: at sentence #1320000, processed 16777430 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,070 : INFO : PROGRESS: at sentence #1330000, processed 16903807 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,165 : INFO : PROGRESS: at sentence #1340000, processed 17032440 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,256 : INFO : PROGRESS: at sentence #1350000, processed 17160064 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,325 : INFO : PROGRESS: at sentence #1360000, processed 17284256 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,398 : INFO : PROGRESS: at sentence #1370000, processed 17410671 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,475 : INFO : PROGRESS: at sentence #1380000, processed 17534001 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,548 : INFO : PROGRESS: at sentence #1390000, processed 17656644 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,619 : INFO : PROGRESS: at sentence #1400000, processed 17777678 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,693 : INFO : PROGRESS: at sentence #1410000, processed 17902075 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,760 : INFO : PROGRESS: at sentence #1420000, processed 18028085 words, keeping 46636 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:28:15,831 : INFO : PROGRESS: at sentence #1430000, processed 18153979 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,909 : INFO : PROGRESS: at sentence #1440000, processed 18281471 words, keeping 46636 word types\n",
      "2017-10-12 16:28:15,976 : INFO : PROGRESS: at sentence #1450000, processed 18405272 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,050 : INFO : PROGRESS: at sentence #1460000, processed 18530502 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,130 : INFO : PROGRESS: at sentence #1470000, processed 18653952 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,234 : INFO : PROGRESS: at sentence #1480000, processed 18781244 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,327 : INFO : PROGRESS: at sentence #1490000, processed 18904879 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,391 : INFO : PROGRESS: at sentence #1500000, processed 19029960 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,447 : INFO : PROGRESS: at sentence #1510000, processed 19153673 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,521 : INFO : PROGRESS: at sentence #1520000, processed 19276961 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,573 : INFO : PROGRESS: at sentence #1530000, processed 19402368 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,658 : INFO : PROGRESS: at sentence #1540000, processed 19526637 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,756 : INFO : PROGRESS: at sentence #1550000, processed 19652145 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,847 : INFO : PROGRESS: at sentence #1560000, processed 19775341 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,923 : INFO : PROGRESS: at sentence #1570000, processed 19898517 words, keeping 46636 word types\n",
      "2017-10-12 16:28:16,957 : INFO : collected 46636 word types from a corpus of 19941872 raw words and 1573362 sentences\n",
      "2017-10-12 16:28:16,960 : INFO : Loading a fresh vocabulary\n",
      "2017-10-12 16:28:17,166 : INFO : min_count=3 retains 31602 unique words (67% of original 46636, drops 15034)\n",
      "2017-10-12 16:28:17,168 : INFO : min_count=3 leaves 19911804 word corpus (99% of original 19941872, drops 30068)\n",
      "2017-10-12 16:28:17,331 : INFO : deleting the raw counts dictionary of 46636 items\n",
      "2017-10-12 16:28:17,333 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-10-12 16:28:17,336 : INFO : downsampling leaves estimated 18760367 word corpus (94.2% of prior 19911804)\n",
      "2017-10-12 16:28:17,338 : INFO : estimated required memory for 31602 words and 120 dimensions: 46138920 bytes\n",
      "2017-10-12 16:28:17,602 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "mulLanguage.build_vocab(token_line_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19941872"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_word = 0\n",
    "for word in token_line_first:\n",
    "    count_word = count_word + len(word)\n",
    "count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:31:22,384 : INFO : training model with 4 workers on 31602 vocabulary and 120 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2017-10-12 16:31:23,401 : INFO : PROGRESS: at 0.05% examples, 627786 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:24,413 : INFO : PROGRESS: at 0.11% examples, 671932 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:25,421 : INFO : PROGRESS: at 0.17% examples, 684411 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:26,427 : INFO : PROGRESS: at 0.23% examples, 691004 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:31:27,455 : INFO : PROGRESS: at 0.30% examples, 699242 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:28,457 : INFO : PROGRESS: at 0.34% examples, 674984 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:31:29,473 : INFO : PROGRESS: at 0.39% examples, 661923 words/s, in_qsize 6, out_qsize 1\n",
      "2017-10-12 16:31:30,474 : INFO : PROGRESS: at 0.44% examples, 646163 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:31:31,482 : INFO : PROGRESS: at 0.48% examples, 628290 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:32,497 : INFO : PROGRESS: at 0.54% examples, 640531 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:31:33,505 : INFO : PROGRESS: at 0.60% examples, 647497 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:34,511 : INFO : PROGRESS: at 0.67% examples, 656556 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:35,517 : INFO : PROGRESS: at 0.73% examples, 664281 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:36,526 : INFO : PROGRESS: at 0.80% examples, 670646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:37,538 : INFO : PROGRESS: at 0.86% examples, 676125 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:38,541 : INFO : PROGRESS: at 0.92% examples, 678942 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:39,548 : INFO : PROGRESS: at 0.99% examples, 683516 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:40,551 : INFO : PROGRESS: at 1.05% examples, 687698 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:41,556 : INFO : PROGRESS: at 1.11% examples, 691363 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:42,569 : INFO : PROGRESS: at 1.18% examples, 694836 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:43,579 : INFO : PROGRESS: at 1.24% examples, 695879 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:44,596 : INFO : PROGRESS: at 1.29% examples, 695318 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:31:45,605 : INFO : PROGRESS: at 1.34% examples, 690652 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:46,610 : INFO : PROGRESS: at 1.39% examples, 686389 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:31:47,621 : INFO : PROGRESS: at 1.46% examples, 688287 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:48,629 : INFO : PROGRESS: at 1.52% examples, 689459 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:49,632 : INFO : PROGRESS: at 1.59% examples, 691982 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:50,634 : INFO : PROGRESS: at 1.65% examples, 694423 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:51,638 : INFO : PROGRESS: at 1.71% examples, 695982 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:52,640 : INFO : PROGRESS: at 1.78% examples, 698120 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:53,651 : INFO : PROGRESS: at 1.84% examples, 699018 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:54,656 : INFO : PROGRESS: at 1.90% examples, 700819 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:55,667 : INFO : PROGRESS: at 1.96% examples, 702431 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:56,677 : INFO : PROGRESS: at 2.03% examples, 703934 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:57,687 : INFO : PROGRESS: at 2.09% examples, 705374 words/s, in_qsize 6, out_qsize 0\n",
      "2017-10-12 16:31:58,696 : INFO : PROGRESS: at 2.15% examples, 705730 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:31:59,700 : INFO : PROGRESS: at 2.22% examples, 707087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:00,707 : INFO : PROGRESS: at 2.27% examples, 705901 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:01,711 : INFO : PROGRESS: at 2.32% examples, 702720 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:02,718 : INFO : PROGRESS: at 2.37% examples, 699828 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:03,723 : INFO : PROGRESS: at 2.43% examples, 700337 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:04,724 : INFO : PROGRESS: at 2.50% examples, 701540 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:05,740 : INFO : PROGRESS: at 2.56% examples, 702683 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:06,747 : INFO : PROGRESS: at 2.63% examples, 704112 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:07,756 : INFO : PROGRESS: at 2.69% examples, 705012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:08,764 : INFO : PROGRESS: at 2.75% examples, 705297 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:09,767 : INFO : PROGRESS: at 2.81% examples, 706426 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:10,773 : INFO : PROGRESS: at 2.88% examples, 707477 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:11,779 : INFO : PROGRESS: at 2.94% examples, 708513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:12,788 : INFO : PROGRESS: at 3.00% examples, 709386 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:13,790 : INFO : PROGRESS: at 3.07% examples, 709642 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:14,791 : INFO : PROGRESS: at 3.13% examples, 710446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:15,793 : INFO : PROGRESS: at 3.19% examples, 709784 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:16,794 : INFO : PROGRESS: at 3.24% examples, 707948 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:17,796 : INFO : PROGRESS: at 3.29% examples, 705334 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:18,821 : INFO : PROGRESS: at 3.34% examples, 702858 words/s, in_qsize 6, out_qsize 1\n",
      "2017-10-12 16:32:19,826 : INFO : PROGRESS: at 3.40% examples, 703663 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:20,828 : INFO : PROGRESS: at 3.46% examples, 704622 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:21,844 : INFO : PROGRESS: at 3.52% examples, 704593 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:22,846 : INFO : PROGRESS: at 3.58% examples, 704249 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:23,857 : INFO : PROGRESS: at 3.64% examples, 704143 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:24,861 : INFO : PROGRESS: at 3.70% examples, 704267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:25,863 : INFO : PROGRESS: at 3.76% examples, 704536 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:26,873 : INFO : PROGRESS: at 3.82% examples, 705446 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:27,885 : INFO : PROGRESS: at 3.88% examples, 704594 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:28,906 : INFO : PROGRESS: at 3.92% examples, 701277 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:29,906 : INFO : PROGRESS: at 3.98% examples, 700629 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:30,924 : INFO : PROGRESS: at 4.03% examples, 699283 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:31,925 : INFO : PROGRESS: at 4.09% examples, 699625 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:32,951 : INFO : PROGRESS: at 4.14% examples, 697712 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:33,960 : INFO : PROGRESS: at 4.19% examples, 695631 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:34,969 : INFO : PROGRESS: at 4.24% examples, 693721 words/s, in_qsize 6, out_qsize 1\n",
      "2017-10-12 16:32:35,979 : INFO : PROGRESS: at 4.29% examples, 693781 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:36,984 : INFO : PROGRESS: at 4.35% examples, 693002 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:37,990 : INFO : PROGRESS: at 4.39% examples, 691612 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:38,991 : INFO : PROGRESS: at 4.44% examples, 689816 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:40,002 : INFO : PROGRESS: at 4.50% examples, 689442 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:41,009 : INFO : PROGRESS: at 4.55% examples, 689195 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:42,012 : INFO : PROGRESS: at 4.61% examples, 688179 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:32:43,028 : INFO : PROGRESS: at 4.67% examples, 688260 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:44,036 : INFO : PROGRESS: at 4.72% examples, 687469 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:45,042 : INFO : PROGRESS: at 4.78% examples, 687408 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:46,065 : INFO : PROGRESS: at 4.83% examples, 686537 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:32:47,076 : INFO : PROGRESS: at 4.88% examples, 685883 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:48,081 : INFO : PROGRESS: at 4.94% examples, 685090 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:49,099 : INFO : PROGRESS: at 4.98% examples, 682686 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:32:50,122 : INFO : PROGRESS: at 5.02% examples, 680509 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:51,135 : INFO : PROGRESS: at 5.06% examples, 678456 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:52,156 : INFO : PROGRESS: at 5.11% examples, 677342 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:53,160 : INFO : PROGRESS: at 5.16% examples, 676267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:54,177 : INFO : PROGRESS: at 5.21% examples, 675325 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:55,181 : INFO : PROGRESS: at 5.27% examples, 675320 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:56,192 : INFO : PROGRESS: at 5.32% examples, 674655 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:57,197 : INFO : PROGRESS: at 5.38% examples, 675516 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:32:58,209 : INFO : PROGRESS: at 5.44% examples, 675352 words/s, in_qsize 6, out_qsize 1\n",
      "2017-10-12 16:32:59,218 : INFO : PROGRESS: at 5.50% examples, 675691 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:00,223 : INFO : PROGRESS: at 5.56% examples, 676244 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:01,226 : INFO : PROGRESS: at 5.63% examples, 676991 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:02,230 : INFO : PROGRESS: at 5.69% examples, 677723 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:03,230 : INFO : PROGRESS: at 5.75% examples, 678184 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:04,246 : INFO : PROGRESS: at 5.81% examples, 678617 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:05,252 : INFO : PROGRESS: at 5.86% examples, 677913 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:06,289 : INFO : PROGRESS: at 5.91% examples, 676940 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:07,296 : INFO : PROGRESS: at 5.97% examples, 676272 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:08,312 : INFO : PROGRESS: at 6.02% examples, 675903 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:09,324 : INFO : PROGRESS: at 6.07% examples, 675665 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:10,325 : INFO : PROGRESS: at 6.13% examples, 675575 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:11,326 : INFO : PROGRESS: at 6.19% examples, 675396 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:12,329 : INFO : PROGRESS: at 6.25% examples, 675567 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:13,345 : INFO : PROGRESS: at 6.31% examples, 676069 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:14,347 : INFO : PROGRESS: at 6.37% examples, 676738 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:15,356 : INFO : PROGRESS: at 6.44% examples, 677525 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:16,364 : INFO : PROGRESS: at 6.50% examples, 678302 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:17,364 : INFO : PROGRESS: at 6.57% examples, 679023 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:18,368 : INFO : PROGRESS: at 6.63% examples, 679621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:19,376 : INFO : PROGRESS: at 6.69% examples, 680114 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:20,383 : INFO : PROGRESS: at 6.75% examples, 680440 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:33:21,389 : INFO : PROGRESS: at 6.80% examples, 679669 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:22,391 : INFO : PROGRESS: at 6.85% examples, 678926 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:23,396 : INFO : PROGRESS: at 6.91% examples, 678796 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:24,411 : INFO : PROGRESS: at 6.97% examples, 679384 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:25,416 : INFO : PROGRESS: at 7.04% examples, 680025 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:26,425 : INFO : PROGRESS: at 7.10% examples, 680705 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:27,441 : INFO : PROGRESS: at 7.16% examples, 680736 words/s, in_qsize 7, out_qsize 1\n",
      "2017-10-12 16:33:28,451 : INFO : PROGRESS: at 7.21% examples, 680282 words/s, in_qsize 4, out_qsize 0\n",
      "2017-10-12 16:33:29,456 : INFO : PROGRESS: at 7.27% examples, 680300 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:30,476 : INFO : PROGRESS: at 7.33% examples, 680028 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:31,514 : INFO : PROGRESS: at 7.38% examples, 679728 words/s, in_qsize 7, out_qsize 1\n",
      "2017-10-12 16:33:32,521 : INFO : PROGRESS: at 7.42% examples, 678436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:33,523 : INFO : PROGRESS: at 7.47% examples, 677774 words/s, in_qsize 8, out_qsize 0\n",
      "2017-10-12 16:33:34,533 : INFO : PROGRESS: at 7.53% examples, 677353 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:35,547 : INFO : PROGRESS: at 7.57% examples, 676361 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:36,609 : INFO : PROGRESS: at 7.61% examples, 674022 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:33:37,628 : INFO : PROGRESS: at 7.64% examples, 672419 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:38,631 : INFO : PROGRESS: at 7.68% examples, 670444 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:39,648 : INFO : PROGRESS: at 7.73% examples, 669569 words/s, in_qsize 7, out_qsize 0\n",
      "2017-10-12 16:33:40,664 : INFO : PROGRESS: at 7.78% examples, 669203 words/s, in_qsize 5, out_qsize 2\n",
      "2017-10-12 16:33:41,696 : INFO : PROGRESS: at 7.84% examples, 668842 words/s, in_qsize 8, out_qsize 1\n",
      "2017-10-12 16:33:42,557 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-10-12 16:33:42,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-10-12 16:33:42,585 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-10-12 16:33:42,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-10-12 16:33:42,595 : INFO : training on 99709360 raw words (93799768 effective words) took 140.2s, 669055 effective words/s\n",
      "2017-10-12 16:33:42,596 : WARNING : supplied example count (7866810) did not equal expected count (99709360)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93799768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulLanguage.train(token_line_first,total_examples =count_word  ,epochs = thrones2vec.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:34:09,390 : INFO : saving Word2Vec object under trained\\mulLanguage.w2v, separately None\n",
      "2017-10-12 16:34:09,392 : INFO : not storing attribute syn0norm\n",
      "2017-10-12 16:34:09,394 : INFO : not storing attribute cum_table\n",
      "2017-10-12 16:34:12,132 : INFO : saved trained\\mulLanguage.w2v\n"
     ]
    }
   ],
   "source": [
    "mulLanguage.save(os.path.join(\"trained\", \"mulLanguage.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:34:17,850 : INFO : loading Word2Vec object from trained\\mulLanguage.w2v\n",
      "2017-10-12 16:34:18,469 : INFO : loading wv recursively from trained\\mulLanguage.w2v.wv.* with mmap=None\n",
      "2017-10-12 16:34:18,470 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-10-12 16:34:18,472 : INFO : setting ignored attribute cum_table to None\n",
      "2017-10-12 16:34:18,474 : INFO : loaded trained\\mulLanguage.w2v\n"
     ]
    }
   ],
   "source": [
    "mulLanguage = w2v.Word2Vec.load(os.path.join(\"trained\", \"mulLanguage.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:34:24,587 : INFO : storing 31602x120 projection weights into temp1.txt\n"
     ]
    }
   ],
   "source": [
    "mulLanguage.wv.save_word2vec_format('temp1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_line_first = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-12 16:35:43,777 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('austria', 0.7070868015289307),\n",
       " ('belgium', 0.6816017031669617),\n",
       " ('holland', 0.6705523729324341),\n",
       " ('netherlands', 0.6674951314926147),\n",
       " ('france', 0.6655858755111694),\n",
       " ('italy', 0.6451388597488403),\n",
       " ('finland', 0.6336227059364319),\n",
       " ('sweden', 0.6013357639312744),\n",
       " ('denmark', 0.5805990099906921),\n",
       " ('spain', 0.5774657130241394)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulLanguage.most_similar(\"germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15232758169217991"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mulLanguage.similarity(\"paris\",\"germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multipal word similarity\n",
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = mulLanguage.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    #return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "international is related to century, as rationale is related to philosophy\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul(\"international\", \"century\", \"philosophy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('temp1.txt', delimiter=' ',skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x[:1000]\n",
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_mean = []\n",
    "for i in y:\n",
    "    y_mean.append([i.mean()])\n",
    "y = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear',cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(y_mean,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98499999999999999"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(y_mean,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
